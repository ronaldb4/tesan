## Introduction

This project is principally a refactoring of the code found at 
https://github.com/Xueping/tesan. This code was provided 
as support for [the paper "Temporal Self-Attention Network for Medical Concept Embedding"](https://ieeexplore.ieee.org/abstract/document/8970822?casa_token=Q_SWfa9NTwsAAAAA:IUafx0x8lOSblA3V7HcFVRO9F5ruk7p8XUyhAzTv00qGqCdPRrFnIU9ZWQfqX0snGqbdwWe96w) 
authored by Xueping Peng; Guodong Long; Tao Shen; Sen Wang; Jing Jiang; Michael Blumenstein 

The purpose of the paper is to present a new embedding method that accommodates the 
temporal aspect of medical data (visits and their diagnoses, procedures). The goal of
this new method is to produced improved embeddings for building machine learning 
algorithms for health care applications.


## About This Project
The goal of the refactor is to make clearer the purposes and difference between the 
assorted models presented in the paper.

Within the paper, nine (9) models are discussed:

- The proposed model
  - TeSAN
- Five (5) baseline models
  - CBOW
  - Skip-Gram
  - GloVe
  - med2vec
  - MCE
- Three (3) ablation models
  - Normal Self-Attention
  - Interval
  - Multiple Self-Attention

Of the nine (9) models discussed in the paper, the original code provides for executing the proposed model, CBOW and the
3 ablation models.

In addition to these models, the original code also specifies three (3) additional models:
- TeSA
- TA_attn
- Fusion

These additional models are represented in the refactor, however (with the exception of TeSA) they have not been 
tested/executed.

Beyond generating embeddings, the original code provides for creating mortality 
prediction models based upon the embeddings generated by the nine discussed models. The 
purpose is not to create effective prediction models, but as an additional test to demonstrate the relative merits of 
the proposed embedding mechanism.

## Executing the Code

There are 4 steps required to execute the code:

0. Acquire the Source Data
1. Pre-process the Source Data
2. Train Embedding Models
3. Train Mortality Prediction Models

### Step 0 - Acquire the Source Data

The full collection of models can be run against the MIMIC-III dataset. This is a controlled access dataset available 
through PhysioNet.  Once you have acquired the files, create a **dataset/mimic3** directory path at the same level as 
the **src** directory.

Into this new directory, you will need to unzip the following files:
- ADMISSIONS.csv
- DIAGNOSES_ICD.csv
- DRGCODES.csv
- PRESCRIPTIONS.csv
- PROCEDURES_ICD.csv

In addition to MIMIC-III, the embedding generation models also support the CMS' Data Entrepreneurs Synthetic Public Use 
File (DE-SynPUF) Dataset available at https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DE_Syn_PUF.  
(The mortality prediction models do *not* support this dataset as it lacks a field equivalent to the "death flag" found 
in MIMIC-III.)

These files should be loaded into a folder path named **dataset/cms** at the same level as the **src** directory.

For your convenience, we have provided the **src/download_cms.sh** shell script. This script has not been fully-tested, 
but we expect it to work on Linux or MacOS *(worst case, it will at least tell which files you need from within the 
DE-SynPUF and where they are located)*

### Step 1 - Pre-process the Source Data

Execute **src/data_preparation.py** 

This script accepts 1 command-line parameter:
- data_source 

```commandline
python data_preparation.py --data_source mimic
```
The valid values are 'cms' or 'mimic'. The default value is 'cms'. 

This will prepare the data for the models.

### Step 2 - Train Embedding Models

Execute **src/train_embedding.py**

The script has 2 required command-line parameters:
- model
- configSet

```commandline
python train_embedding.py --model tesan --configSet concept_embedding/mimic_paper.json
```

The **model** parameter specifies the model being used to generate embedings. The supported/tested
options are:

| Parameter Value | Model |
|-----------------| ----- |
| tesan           | TeSAN |
| cbow            | CBOW |
| sa              | Multiple Self-Attention |
| delta           | Interval |
| multi           | Multiple Self-Attention |
| tesa | TeSA |

The **configSet** parameter specifies the JSON file to be used to specify the hyper-parameters that define 
the behavior of the both the model and the treatment of the data (the versions used to generate the metrics in 
our paper are provided in the repository.) *For details on key hyperparameters, see the accompanying paper.* 

### Step 3 - Train Mortality Prediction Models

Execute **src/train_prediction.py**

The script requires the same 2 command-line parameters as *train_embedding.py*: 
- model
- configSet

```commandline
python train_prediction.py --model tesan --configSet mortality_prediction/mimic_paper.json
```
   
## Outputs

The models will output their results to a folder named **outputs/concept_embedding** or **outputs/mortality_prediction** 
(when running Embedding Generation or Mortality Prediction model, respectively).  This folder will be created at the 
same level as the **src** folder.

Within these folders, a sub-folder is created for the particular model you are executing *(per the --model parameter 
passed into the training script above)*.

Within this sub-folder will be created 5 sub-folders:
- cpkt
- log_files
- processed_data
- summary
- vects

Of these, the most significant are **log_files** and **vects**.
- **log_files** contains the logs of your model training executions. Within those logs are all of the metrics presented 
in the paper.
- **vects** contains the embedding vectors generated by the models. The vects generated by the *concept_embedding* 
models are a critical input into the *mortality_prediction* models.


#### Note: Execution Environment and Locally Installed Packages

All model executions were performed within PyCharm with the following packages installed (not all are necessarily used 
by this project, but all are listed due to potential dependency chains):

|Package              |Version|
|---------------------|--------|
|absl-py              |0.15.0|
|astor                |0.8.1|
|Bottleneck           |1.3.2|
|cached-property      |1.5.2|
|certifi              |2021.10.8|
|gast                 |0.5.3|
|grpcio               |1.42.0|
|h5py                 |3.6.0|
|importlib-metadata   |4.8.2|
|joblib               |1.1.0|
|Keras-Applications   |1.0.8|
|Keras-Preprocessing  |1.1.2|
|Markdown             |3.3.4|
|mkl-fft              |1.3.1|
|mkl-random           |1.2.2|
|mkl-service          |2.4.0|
|numexpr              |2.8.1|
|numpy                |1.21.2|
|packaging            |21.3|
|pandas               |1.3.4|
|pip                  |21.2.2|
|protobuf             |3.19.1|
|psutil               |5.8.0|
|pyparsing            |3.0.4|
|python-dateutil      |2.8.2|
|pytz                 |2021.3|
|scikit-learn         |1.0.2|
|scipy                |1.7.3|
|setuptools           |58.0.4|
|six                  |1.16.0|
|tensorboard          |1.14.0|
|tensorflow           |1.14.0|
|tensorflow-estimator |1.14.0|
|termcolor            |1.1.0|
|threadpoolctl        |2.2.0|
|typing-extensions    |3.10.0.2|
|Werkzeug             |2.0.3|
|wheel                |0.37.1|
|wrapt                |1.13.3|
|zipp                 |3.7.0|


